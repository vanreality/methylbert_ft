{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78960ddb-9513-4e32-8a13-2e67da98d761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:57:49.489986Z",
     "iopub.status.busy": "2024-12-12T06:57:49.489732Z",
     "iopub.status.idle": "2024-12-12T06:58:01.913085Z",
     "shell.execute_reply": "2024-12-12T06:58:01.912674Z",
     "shell.execute_reply.started": "2024-12-12T06:57:49.489973Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deacde0b-78b9-4cb5-8981-56aaf4732c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:58:01.914012Z",
     "iopub.status.busy": "2024-12-12T06:58:01.913748Z",
     "iopub.status.idle": "2024-12-12T06:58:01.920785Z",
     "shell.execute_reply": "2024-12-12T06:58:01.920517Z",
     "shell.execute_reply.started": "2024-12-12T06:58:01.913996Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_matplotlib_style():\n",
    "    plt.rcParams['figure.figsize'] = (12,8)  # 图形大小\n",
    "    plt.rcParams['axes.titlesize'] = 18       # 标题字体大小\n",
    "    plt.rcParams['axes.labelsize'] = 15       # x轴和y轴标签字体大小\n",
    "    plt.rcParams['xtick.labelsize'] = 12      # x轴刻度字体大小\n",
    "    plt.rcParams['ytick.labelsize'] = 12      # y轴刻度字体大小\n",
    "    plt.rcParams['legend.fontsize'] = 12      # 图例字体大小\n",
    "    plt.rcParams['axes.linewidth'] = 2      # 坐标轴线宽\n",
    "    plt.rcParams['xtick.major.size'] = 5      # x轴主刻度大小\n",
    "    plt.rcParams['ytick.major.size'] = 5      # y轴主刻度大小\n",
    "    plt.rcParams['xtick.major.width'] = 1.5   # x轴主刻度线宽\n",
    "    plt.rcParams['ytick.major.width'] = 1.5   # y轴主刻度线宽\n",
    "    plt.rcParams['lines.linewidth'] = 2       # 线条宽度\n",
    "    plt.rcParams['lines.markersize'] = 8      # 标记大小\n",
    "    plt.rcParams['savefig.dpi'] = 300         # 保存图片分辨率\n",
    "    plt.rcParams['savefig.format'] = 'pdf'    # 图片保存格式\n",
    "    plt.rcParams['grid.alpha'] = 0.6          # 网格线透明度\n",
    "    # plt.rcParams['grid.linestyle'] = '--'     # 网格线样式\n",
    "    # plt.rcParams['grid.linewidth'] = 0.7      # 网格线宽度\n",
    "    plt.rcParams['axes.grid'] = False          # 网格\n",
    "    plt.rcParams['axes.edgecolor'] = 'black'  # 边框颜色\n",
    "    plt.rcParams['axes.titlepad'] = 15        # 标题与图形之间的距离\n",
    "    plt.rcParams['legend.frameon'] = False    # 去掉图例边框\n",
    "    \n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    loss_list = []\n",
    "    lr_list = []\n",
    "    steps = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = re.search(r'Train Step (\\d+) iter - loss : ([\\d.]+) / lr : ([\\d.]+)', line)\n",
    "            if match:\n",
    "                step = int(match.group(1))\n",
    "                loss = float(match.group(2))\n",
    "                lr = float(match.group(3))\n",
    "                steps.append(step)\n",
    "                loss_list.append(loss)\n",
    "                lr_list.append(lr)\n",
    "    return steps, loss_list, lr_list\n",
    "\n",
    "\n",
    "def parse_eval_file(file_path):\n",
    "    loss_list = []\n",
    "    steps = []\n",
    "\n",
    "    eval_res_df = pd.read_csv(file_path, sep='\\t')\n",
    "    steps = eval_res_df['step'].tolist()\n",
    "    loss_list = eval_res_df['loss'].tolist()\n",
    "\n",
    "    return steps, loss_list\n",
    "\n",
    "\n",
    "def downsample_and_smooth(data, steps_per_epoch, downsample_rate=20, sigma=2):\n",
    "    \"\"\"\n",
    "    Downsample the data to every `steps_per_epoch // downsample_rate` and smooth it.\n",
    "    \"\"\"\n",
    "    sampled_indices = list(range(0, len(data), steps_per_epoch // downsample_rate))\n",
    "    sampled_data = [data[i] for i in sampled_indices]\n",
    "    smoothed_data = gaussian_filter1d(sampled_data, sigma=sigma)\n",
    "    return sampled_indices, smoothed_data\n",
    "    \n",
    "\n",
    "def plot_curves(log_path, eval_path, out_path):\n",
    "    set_matplotlib_style()\n",
    "    \n",
    "    # Parse log and evaluation files\n",
    "    train_steps, train_loss_list, lr_list = parse_log_file(log_path)\n",
    "    eval_steps, eval_loss_list = parse_eval_file(eval_path)\n",
    "\n",
    "    # Get steps per epoch from the evaluation file\n",
    "    steps_per_epoch = eval_steps[1] - eval_steps[0] if len(eval_steps) > 1 else len(train_steps)\n",
    "\n",
    "    # Downsample and smooth the training loss\n",
    "    sampled_indices, smoothed_train_loss = downsample_and_smooth(train_loss_list, steps_per_epoch)\n",
    "    \n",
    "    # Plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(sampled_indices, smoothed_train_loss, label='Training Loss', color='blue')\n",
    "    plt.plot(eval_steps, eval_loss_list, label='Test Loss', color='red')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(out_path, 'loss.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot learning rate curve\n",
    "    plt.plot(train_steps, lr_list, label='Learning Rate', color='orange')\n",
    "    plt.title('Learning Rate Curve')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(out_path, 'learning_rates.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d2a531-4d61-44e6-8737-0bd1a2dc169a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:38:32.345324Z",
     "iopub.status.busy": "2024-12-12T10:38:32.345088Z",
     "iopub.status.idle": "2024-12-12T10:38:32.929181Z",
     "shell.execute_reply": "2024-12-12T10:38:32.928736Z",
     "shell.execute_reply.started": "2024-12-12T10:38:32.345309Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_list = ['dlbcl', 'lica', 'senescence', 'pl_wbc', 'pl_cfdna', 'pl_cfdna_sped9k']\n",
    "dataset_list = ['dlbcl_val', 'leucocyte_val', 'pl_wbc_val']\n",
    "for dataset in dataset_list:\n",
    "    log_path = f'./benchmark_{dataset}.log'\n",
    "    eval_path = os.path.join('../results/benchmark', dataset, '1.finetune/bert.model/eval.csv')\n",
    "    out_path = os.path.join('../results/benchmark', dataset, '2.plot')\n",
    "    plot_curves(log_path, eval_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13186015-e055-4331-b6f0-d55507aa92fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T01:16:10.546689Z",
     "iopub.status.busy": "2024-12-08T01:16:10.546487Z",
     "iopub.status.idle": "2024-12-08T01:16:11.279663Z",
     "shell.execute_reply": "2024-12-08T01:16:11.279289Z",
     "shell.execute_reply.started": "2024-12-08T01:16:10.546678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined loss curves saved at ../results/benchmark/combined_loss_curves.pdf\n"
     ]
    }
   ],
   "source": [
    "def plot_combined_curves(dataset_list, output_path):\n",
    "    \"\"\"\n",
    "    将多个数据集的 Loss 曲线拼接到一张图中\n",
    "\n",
    "    Parameters:\n",
    "    dataset_list (list): 数据集名称列表\n",
    "    output_path (str): 保存总图的输出路径\n",
    "    \"\"\"\n",
    "    set_matplotlib_style()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, dataset in enumerate(dataset_list):\n",
    "        log_path = f'./benchmark_{dataset}.log'\n",
    "        eval_path = os.path.join('../results/benchmark', dataset, '1.finetune/bert.model/eval.csv')\n",
    "\n",
    "        # Parse log and evaluation files\n",
    "        train_steps, train_loss_list, lr_list = parse_log_file(log_path)\n",
    "        eval_steps, eval_loss_list = parse_eval_file(eval_path)\n",
    "\n",
    "        # Get steps per epoch from the evaluation file\n",
    "        steps_per_epoch = eval_steps[1] - eval_steps[0] if len(eval_steps) > 1 else len(train_steps)\n",
    "\n",
    "        # Downsample and smooth the training loss\n",
    "        sampled_indices, smoothed_train_loss = downsample_and_smooth(train_loss_list, steps_per_epoch)\n",
    "        \n",
    "        # Plot on the corresponding subplot\n",
    "        ax = axes[idx]\n",
    "        ax.plot(sampled_indices, smoothed_train_loss, label='Training Loss', color='blue')\n",
    "        ax.plot(eval_steps, eval_loss_list, label='Test Loss', color='red')\n",
    "        ax.set_title(f'Loss Curve - {dataset}', fontsize=12)\n",
    "        ax.set_xlabel('Steps')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.grid(True)\n",
    "        ax.legend(fontsize=10)\n",
    "    \n",
    "    # Remove unused subplots if dataset_list has fewer than 6 datasets\n",
    "    for idx in range(len(dataset_list), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    # Adjust layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    combined_plot_path = os.path.join(output_path, 'combined_loss_curves.pdf')\n",
    "    plt.savefig(combined_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Combined loss curves saved at {combined_plot_path}\")\n",
    "\n",
    "output_path = '../results/benchmark'\n",
    "plot_combined_curves(dataset_list, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e600c44-d73d-4a21-b0a4-60d5b761a0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T00:59:59.545720Z",
     "iopub.status.busy": "2024-12-08T00:59:59.545485Z",
     "iopub.status.idle": "2024-12-08T00:59:59.548356Z",
     "shell.execute_reply": "2024-12-08T00:59:59.548067Z",
     "shell.execute_reply.started": "2024-12-08T00:59:59.545708Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions_df):\n",
    "    true_labels = predictions_df['ctype'].map({'T': 1, 'N': 0}).values\n",
    "    predicted_probs = predictions_df['P_ctype'].values\n",
    "    \n",
    "    predicted_labels = (predicted_probs > 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(true_labels, predicted_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    roc_auc = roc_auc_score(true_labels, predicted_probs)\n",
    "    \n",
    "    return {\"ACC\": acc, \"PR-AUC\": pr_auc, \"ROC-AUC\": roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c0b21a6-dd66-4f79-a934-4e9e2c5118c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:34.920148Z",
     "iopub.status.busy": "2024-12-09T08:59:34.919902Z",
     "iopub.status.idle": "2024-12-09T08:59:45.493519Z",
     "shell.execute_reply": "2024-12-09T08:59:45.493146Z",
     "shell.execute_reply.started": "2024-12-09T08:59:34.920135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics of dlbcl are: ROC-AUC=0.8482, PR-AUC=0.7825, ACC=0.7760\n",
      "The metrics of lica are: ROC-AUC=0.8334, PR-AUC=0.8303, ACC=0.7421\n",
      "The metrics of senescence are: ROC-AUC=0.7528, PR-AUC=0.6780, ACC=0.7039\n",
      "The metrics of pl_wbc are: ROC-AUC=0.8592, PR-AUC=0.9751, ACC=0.8601\n",
      "The metrics of pl_cfdna are: ROC-AUC=0.9019, PR-AUC=0.9159, ACC=0.8217\n",
      "The metrics of pl_cfdna_sped9k are: ROC-AUC=0.9053, PR-AUC=0.9128, ACC=0.8401\n",
      "The metrics of dlbcl_mut are: ROC-AUC=0.8544, PR-AUC=0.8631, ACC=0.7544\n",
      "The metrics of leucocyte are: ROC-AUC=0.6805, PR-AUC=0.4508, ACC=0.7939\n"
     ]
    }
   ],
   "source": [
    "dataset_list = ['dlbcl', 'lica', 'senescence', 'pl_wbc', 'pl_cfdna', 'pl_cfdna_sped9k', 'dlbcl_mut', 'leucocyte']\n",
    "for dataset in dataset_list:\n",
    "    res_df = pd.read_csv(os.path.join('../results/benchmark', dataset, '3.deconvolute/res.csv'), sep='\\t')\n",
    "    metrics = calculate_metrics(res_df)\n",
    "    print(f'The metrics of {dataset} are: ROC-AUC={metrics[\"ROC-AUC\"]:.4f}, PR-AUC={metrics[\"PR-AUC\"]:.4f}, ACC={metrics[\"ACC\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcdef2-726c-4700-b5e0-aeaa2d9125eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
